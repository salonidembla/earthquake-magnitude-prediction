{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ebeb032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91860\\AppData\\Local\\Temp\\ipykernel_24372\\2441033078.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.fillna(0, inplace=True)  # Option to fill other missing values with 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.1385918101995335\n",
      "R² Score: 0.784377619541546\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "file_path = 'filtered_earthquake_data.csv'  # Adjust the path if needed\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 3: Select relevant features\n",
    "# Features: Include a wider range of columns from the dataset for better model accuracy\n",
    "X = data[['source_depth_km', 'source_distance_km', 'receiver_latitude', \n",
    "          'receiver_longitude', 'receiver_elevation_m', 'source_latitude', \n",
    "          'source_longitude', 'source_horizontal_uncertainty_km', 'p_weight', \n",
    "          's_weight', 'p_travel_sec', 's_arrival_sample', 'back_azimuth_deg']]\n",
    "\n",
    "# Step 4: Define the target variable\n",
    "y = data['source_magnitude']  # Assuming we are predicting 'source_magnitude'\n",
    "\n",
    "# Step 5: Handle missing values\n",
    "X.fillna(0, inplace=True) \n",
    "\n",
    "# Step 6: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 7: Create and train the Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)  # You can adjust n_estimators for a bigger or smaller forest\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Make predictions\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "# Step 9: Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Step 10: Print the evaluation metrics\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R² Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c0d6f93",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_regressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9180\\4247294723.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtree_depths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_depth\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrf_regressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Depth of each tree: {tree_depths}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Average tree depth: {sum(tree_depths) / len(tree_depths)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rf_regressor' is not defined"
     ]
    }
   ],
   "source": [
    "tree_depths = [estimator.tree_.max_depth for estimator in rf_regressor.estimators_]\n",
    "print(f\"Depth of each tree: {tree_depths}\")\n",
    "print(f\"Average tree depth: {sum(tree_depths) / len(tree_depths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec6e72f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 0.33460283301064486\n",
      "Linear Regression R² Score: 0.4794219134736384\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries for Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Step 2: Create a Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Step 3: Train the model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make predictions\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "# Step 6: Print the results\n",
    "print(f\"Linear Regression MSE: {mse_lr}\")\n",
    "print(f\"Linear Regression R² Score: {r2_lr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24ef2616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree MSE: 0.26614606258341983\n",
      "Decision Tree R² Score: 0.5859275704584539\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries for Decision Tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Step 2: Create a Decision Tree Regressor model\n",
    "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Step 3: Train the model\n",
    "dt_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make predictions\n",
    "y_pred_dt = dt_regressor.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
    "r2_dt = r2_score(y_test, y_pred_dt)\n",
    "\n",
    "# Step 6: Print the results\n",
    "print(f\"Decision Tree MSE: {mse_dt}\")\n",
    "print(f\"Decision Tree R² Score: {r2_dt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d61eac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model       MSE  R² Score\n",
      "0  Linear Regression  0.334603  0.479422\n",
      "1      Decision Tree  0.266146  0.585928\n",
      "2      Random Forest  0.138592  0.784378\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to store model results\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Decision Tree', 'Random Forest'],\n",
    "    'MSE': [mse_lr, mse_dt, mse],\n",
    "    'R² Score': [r2_lr, r2_dt, r2]\n",
    "})\n",
    "\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f53e388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.1-py3-none-win_amd64.whl (124.9 MB)\n",
      "     -------------------------------------- 124.9/124.9 MB 1.4 MB/s eta 0:00:00\n",
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.5.0-py3-none-win_amd64.whl (1.4 MB)\n",
      "     ---------------------------------------- 1.4/1.4 MB 3.3 MB/s eta 0:00:00\n",
      "Collecting catboost\n",
      "  Downloading catboost-1.2.7-cp39-cp39-win_amd64.whl (101.8 MB)\n",
      "     -------------------------------------- 101.8/101.8 MB 1.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\users\\91860\\anaconda3\\lib\\site-packages (from xgboost) (1.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\91860\\anaconda3\\lib\\site-packages (from xgboost) (1.24.4)\n",
      "Requirement already satisfied: six in c:\\users\\91860\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\91860\\anaconda3\\lib\\site-packages (from catboost) (1.4.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\91860\\anaconda3\\lib\\site-packages (from catboost) (3.5.2)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "     ---------------------------------------- 47.1/47.1 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: plotly in c:\\users\\91860\\anaconda3\\lib\\site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\91860\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\91860\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\91860\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\91860\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\91860\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\91860\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\91860\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\91860\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\91860\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.0.1)\n",
      "Installing collected packages: graphviz, xgboost, lightgbm, catboost\n",
      "Successfully installed catboost-1.2.7 graphviz-0.20.3 lightgbm-4.5.0 xgboost-2.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost lightgbm catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24f8b77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91860\\AppData\\Local\\Temp\\ipykernel_24372\\2719535844.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.fillna(0, inplace=True)  # Fill other missing values with 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2978\n",
      "[LightGBM] [Info] Number of data points in the train set: 296689, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 1.458754\n",
      "      Model       MSE  R² Score\n",
      "0   XGBoost  0.156662  0.756265\n",
      "1  LightGBM  0.170578  0.734613\n",
      "2  CatBoost  0.168288  0.738176\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "file_path = 'filtered_earthquake_data.csv'  # Adjust the path if needed\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 3: Select relevant features\n",
    "X = data[['source_depth_km', 'source_distance_km', 'receiver_latitude', \n",
    "          'receiver_longitude', 'receiver_elevation_m', 'source_latitude', \n",
    "          'source_longitude', 'source_horizontal_uncertainty_km', 'p_weight', \n",
    "          's_weight', 'p_travel_sec', 's_arrival_sample', 'back_azimuth_deg']]\n",
    "\n",
    "# Step 4: Define the target variable\n",
    "y = data['source_magnitude']  # Assuming we are predicting 'source_magnitude'\n",
    "\n",
    "# Step 5: Handle missing values\n",
    "X.fillna(0, inplace=True)  # Fill other missing values with 0\n",
    "\n",
    "# Step 6: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 7: Create and train the models\n",
    "\n",
    "# XGBoost Regressor\n",
    "xgb_regressor = XGBRegressor(n_estimators=100, random_state=42)\n",
    "xgb_regressor.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_regressor.predict(X_test)\n",
    "\n",
    "# LightGBM Regressor\n",
    "lgbm_regressor = LGBMRegressor(n_estimators=100, random_state=42)\n",
    "lgbm_regressor.fit(X_train, y_train)\n",
    "y_pred_lgbm = lgbm_regressor.predict(X_test)\n",
    "\n",
    "# CatBoost Regressor\n",
    "cat_regressor = CatBoostRegressor(iterations=100, random_state=42, verbose=0)  # verbose=0 to suppress output\n",
    "cat_regressor.fit(X_train, y_train)\n",
    "y_pred_cat = cat_regressor.predict(X_test)\n",
    "\n",
    "# Step 8: Evaluate the models\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "mse_lgbm = mean_squared_error(y_test, y_pred_lgbm)\n",
    "r2_lgbm = r2_score(y_test, y_pred_lgbm)\n",
    "\n",
    "mse_cat = mean_squared_error(y_test, y_pred_cat)\n",
    "r2_cat = r2_score(y_test, y_pred_cat)\n",
    "\n",
    "# Step 9: Print the evaluation metrics\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['XGBoost', 'LightGBM', 'CatBoost'],\n",
    "    'MSE': [mse_xgb, mse_lgbm, mse_cat],\n",
    "    'R² Score': [r2_xgb, r2_lgbm, r2_cat]\n",
    "})\n",
    "\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6949249f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91860\\AppData\\Local\\Temp\\ipykernel_15680\\349830182.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.1385918101995335\n",
      "R² Score: 0.784377619541546\n",
      "Depth of each tree: [50, 52, 53, 53, 56, 54, 55, 52, 52, 51, 52, 56, 49, 55, 51, 52, 55, 56, 53, 59, 53, 51, 54, 54, 52, 51, 53, 55, 51, 57, 56, 56, 54, 52, 57, 54, 52, 50, 54, 49, 53, 59, 55, 59, 53, 51, 51, 50, 52, 56, 55, 64, 52, 55, 51, 51, 54, 54, 55, 54, 51, 52, 58, 55, 50, 51, 56, 59, 55, 55, 53, 51, 53, 53, 51, 53, 51, 57, 51, 62, 58, 53, 51, 53, 52, 52, 50, 52, 56, 52, 65, 55, 51, 56, 53, 51, 53, 56, 55, 48]\n",
      "Average tree depth: 53.64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "file_path = 'filtered_earthquake_data.csv'  # Adjust the path if needed\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 3: Select relevant features\n",
    "X = data[['source_depth_km', 'source_distance_km', 'receiver_latitude', \n",
    "          'receiver_longitude', 'receiver_elevation_m', 'source_latitude', \n",
    "          'source_longitude', 'source_horizontal_uncertainty_km', 'p_weight', \n",
    "          's_weight', 'p_travel_sec', 's_arrival_sample', 'back_azimuth_deg']]\n",
    "\n",
    "# Step 4: Define the target variable\n",
    "y = data['source_magnitude']\n",
    "\n",
    "# Step 5: Handle missing values\n",
    "X.fillna(0, inplace=True)\n",
    "\n",
    "# Step 6: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 7: Create and train the Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Make predictions\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "# Step 9: Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Step 10: Print the evaluation metrics\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R² Score: {r2}\")\n",
    "\n",
    "# Step 11: Calculate and print the depth of each tree\n",
    "tree_depths = [estimator.tree_.max_depth for estimator in rf_regressor.estimators_]\n",
    "print(f\"Depth of each tree: {tree_depths}\")\n",
    "print(f\"Average tree depth: {sum(tree_depths) / len(tree_depths)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9177f9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91860\\AppData\\Local\\Temp\\ipykernel_15680\\2620710169.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Evaluation:\n",
      "Mean Squared Error (MSE): 0.019276659725537503\n",
      "R² Score: 0.9698824900943062\n",
      "\n",
      "Test Data Evaluation:\n",
      "Mean Squared Error (MSE): 0.1385918101995335\n",
      "R² Score: 0.784377619541546\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "file_path = 'filtered_earthquake_data.csv'  # Adjust the path if needed\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 3: Select relevant features\n",
    "X = data[['source_depth_km', 'source_distance_km', 'receiver_latitude', \n",
    "          'receiver_longitude', 'receiver_elevation_m', 'source_latitude', \n",
    "          'source_longitude', 'source_horizontal_uncertainty_km', 'p_weight', \n",
    "          's_weight', 'p_travel_sec', 's_arrival_sample', 'back_azimuth_deg']]\n",
    "\n",
    "# Step 4: Define the target variable\n",
    "y = data['source_magnitude']  # Assuming we are predicting 'source_magnitude'\n",
    "\n",
    "# Step 5: Handle missing values\n",
    "X.fillna(0, inplace=True) \n",
    "\n",
    "# Step 6: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 7: Create and train the Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)  # You can adjust n_estimators for a bigger or smaller forest\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Make predictions on training and test data\n",
    "y_train_pred = rf_regressor.predict(X_train)\n",
    "y_test_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "# Step 9: Evaluate the model on training data\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Step 10: Evaluate the model on test data\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Step 11: Print the evaluation metrics\n",
    "print(\"Training Data Evaluation:\")\n",
    "print(f\"Mean Squared Error (MSE): {train_mse}\")\n",
    "print(f\"R² Score: {train_r2}\")\n",
    "\n",
    "print(\"\\nTest Data Evaluation:\")\n",
    "print(f\"Mean Squared Error (MSE): {test_mse}\")\n",
    "print(f\"R² Score: {test_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35e4e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
